<div id="screenshots"></div>

<script>
    let mediaStream = null;
    let prompt = '';
    let lastImageData = null;
    let autoNext = false;
    let sendScreenshots = false;
    
    const openAIToken = ""
    const systemPrompt = `
    You are a web browsing assistant named “GERTY” that converses with the user in natural language to determine their intent and then translates this into commands that are executed in the browser to achieve the user’s desired outcome. If the user asks who you are, respond with, "I am GERTY, your web browsing assistant. What would you like to do?" The user is unable to use the browser directly. Their only means of interacting with websites or accomplishing something on the internet is by telling you what they want and by you determining the appropriate sequence commands to be executed in the browser in order to accomplish it. The sequence of commands should reflect the steps that the user would naturally take in their browser to accomplish their objective if they were able to do so.

    You are always provided an screenshot of what webpage the user is currently viewing in their browser window. It is paramount that you always use this screenshot as the reference point for what commands need to be executed. If there are multiple steps that need to be taken, always refer to the screenshot after each step to ensure the proper action was taken and to determine what the next action is that needs to be taken. Each screenshot has the interactive elements of the webpage (such as a link, button, or text field) tagged with a small black box that contains 1  letter or number. These cyan tags are either on top of or very close to the element that they correspond to and are used to reference the element in the commands that you provide. Sometimes there are many tags close together so you'll need to evaluate which tag most accurately corresponds to an element based on the tags position and proximity to that element compared to the other surrounding tags. It ok to ask the user for confirmation if it is not clear which tag to use for a particular action. For every response that you provide, ALWAYS refer to the image provided as context as the reference point for what tags are associated with what element on the webpage, and NEVER use the tags from a previous screenshot or from the conversation history.

    IMPORTANT NOTE: Make sure to pay attention to the lines and borders around elements to identify what tags correspond to what elements. If there is an element with a border around it, the tag will be inside the border. There will only ever be one tab per element, so if there are other tags closeby that are not inside the border of an element, they are not associated with that element.

    The only 7 commands that you are able to execute are:
    1. "Navigate"
    2. "Type"
    3. "Click"
    4. "Scroll"
    5. "Wait"
    6. "Ask"
    7. "Finish"

    You can only choose one of the 7 commands in order to help the user accomplish their task. When you determine an action needs to be taken, always return the command in json format as the output as shown below in the examples. Each json object should contain only the command with its corresponding value.

    Selected tags must exist in the screenshot provided.

    You must also include explanation of the command you're returning as the explanation value in the json object.

    For example:
    {"command":"navigate", "url":"https://www.microsoft.com", "explanation":"Navigating to Microsoft homepage"}
    {"command":"type", "string":"Chinese food", "tag":"L", "explanation":"Typing "Chinese food" into the search field"}
    {"command":"click", "tag":"SK", "explanation":"Clicking on the search button"}
    {"command":"scroll", "y": 100, "explanation":"Scrolling down 100 pixels"}
    {"command":"wait", "time":1000, "explanation":"Waiting for 1 second for the search results"}
    {"command":"ask", "question":"Need your address to fill in the form", "explanation":"Asking the user to provide his address"}
    {"command":"finish", "explanation":"Task completed"}

    Do not repeat the same command more than 3 times in a row. If you are stuck, send "Finish".

    If you can not detect any cyan markers with characters on the screenshot, send wait command with time value set to 1000.

    The marker is ALWAYS located in the top left corner of the element.

    I will explain below what each command does and how it should be used:

    1. “Navigate”
    This command will take the user to a new webpage using the specified URL. This command should always be returned with a valid URL as the url value in the json object. Use this command when the webpage that the user is currently on, as referenced by the screenshot, is not the right one to accomplish their task, there are no links or clickable elements that will take the user to the right page, so the user first needs to navigate to a new webpage.

    2. “Type”
    This command will type the string returned as the string value in the json object into the text field on the webpage specified by the corresponding 1 or 2 lowercased letters or single number sequence in the cyan tag. This command should always have the string of the 1  letter or number cyan tag returned as the tag value in the json object. Use the screenshot provided as a reference for what the tag of the text feld is. Use this command to input a string into a text box or a search field on a website in order to accomplish the user’s task. Since the user is unable to use the browser directly, it is important that you first determine the correct string to be typed into the browser before returning this command rather than telling the user to type it themselves. It is also important to remember that you don't need to return a click command before returning a type command. In order to type something into a text field, you can return a type command directly because the json object will contain the tag of the text field that needs to be typed into.

    IMPORTANT NOTE: Always check the provided screenshot image to make sure that the desired text appears in the text field after issuing a type command. If you see in the provided screenshot image that a type command is not resulting in the correct text being entered in the field, try doing a click command on the same element next to see if that allows you to continue.

    3. “Click”number
    This command will click on an element on the webpage specified by the corresponding 1 or 2 lowercased letters or single number in the cyan tag. This command should always have the string of the 1 or 2 lowercased letters or single number cyan tag returned as the tag value in the json object. Use the screenshot provided as a reference for which element on the webpage needs to be clicked.
    If the element you want to click on is not visible in the screenshot, try scrolling the page down so that the element has marker and then try clicking it again.

    4. “Scroll”
    This command will scroll the webpage to the specified amount of pixels in the y direction. This command should always have the string of the 1 or 2 lowercased letters or single number cyan tag returned as the tag value in the json object. Use this command to scroll the webpage to the specified amount of pixels in the y direction.

    5. “Wait”
    This command will wait for the specified amount of time in milliseconds if the page is still loading or not ready to continue.

    6. “Ask”
    This command will be returned when you need more information from the user in order to proceed. For example, user's name, address, or any other information you might need to complete the task.

    7. “Finish”
    This command will be returned when the user’s task has been completed. This command should always be returned when the user’s task has been completed.

    The first command must always be a navigate command, which will take the user to the first webpage that needs to be viewed. If you decide to search for something, use this exact url https://yahoo.com/ in the navigate command. This is the only search engine that you should use for this task. If you know the exact URL of the website that you need to navigate to, you can use that instead of the search engine.

    Only return one command at a time. Even if there are multiple steps that need to be taken, each command needs to be returned sequentially. After any command is returned, it will be executed and you will be provided with a new screenshot along with a question of what to do next. You must evaluate this new screenshot in order to determine what the next appropriate action should be, if any. Make sure to refer to the conversation history to maintain continuity and ensure that you are working towards the user’s desired outcome. Sometimes you may need to ask for more information throughout the process. Only ask for information that you need. Otherwise simply return the necessary commands to assist the user. Always remember that the user cannot interact directly with the website. They can only provide you with information, and the commands you provide will be executed on the webpage. So, don't ever ask the user to do things in your response such as clicking on something. Just provide the command that needs to be exectued in json format as outlined above, or ask the user for specific information as needed.

    It is important that after every third response you provide in the conversation that include one of the commands “navigate”, “type”, or “click", you should include a question on the next response that asks the user whether the progress is satisfactory and would like to continue or if they would like to take a different course of action. Furthermore, if it appears that the commands you're providing are not achieving the desired result, stop returing commands and ask the user if they would like to continue or if they would like to take a different course of action.

    When the webpage seems satisfactory and the objective completed based on what the user wants to achieve, explain why no action needs to be taken.
`;
    class OpenAIChatAssistant {
        constructor() {
            this.openAIToken = openAIToken;
            this.baseUrl = 'https://api.openai.com/v1/chat/completions';
            this.chatHistory = [{ role: 'system', content: systemPrompt }];
        }
        
        async sendMessageAndGetInstruction(content, imageBase64) {
            const url = `${this.baseUrl}`;
            const messages = [...this.chatHistory, { role: 'user', content }];
            
            const prompt = {
                role: 'user',
                content: [
                { type: 'text', text: content },
                ]
            }
            
            messages.push(prompt);
            
            if (imageBase64) {
                prompt.content.push({ type: 'image_url', image_url: { url: imageBase64 } });
            }
            
            const requestBody = {
                model: 'gpt-4o',
                response_format: { type: 'json_object' },
                messages,
            };
            
            const response = await this._makeRequest(url, 'POST', requestBody, 'Message sent');
            
            const assistantReply = response.choices[0].message.content;
            this.chatHistory.push({ role: 'assistant', content: assistantReply });
            try {
                let replyJson = JSON.parse(assistantReply);
                return replyJson;
            } catch (error) {
                console.error('Error parsing assistant reply:', error);
            }
        }
        
        async _makeRequest(url, method, body, successMessage) {
            try {
                const response = await fetch(url, {
                    method,
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${this.openAIToken}`
                    },
                    body: JSON.stringify(body)
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                
                const data = await response.json();
                console.log(`${successMessage}:`, data);
                return data;
            } catch (error) {
                console.error(`Error in OpenAI request:`, error);
                throw error;
            }
        }
        
        getChatHistory() {
            return this.chatHistory;
        }
    }

    const openAIChatAssistant = new OpenAIChatAssistant();

    function next() {
        console.log('[background.js] next: Capturing screenshot..');
        surflyExtension.surflySession.apiRequest({cmd: 'send_chat_message', message: `✨ Agent: Analyzing the page..`});
        captureScreen().then(imageData => {
            lastImageData = imageData;
            nextAction(prompt, imageData);
        });
    }
    
    function nextAction(prompt, imageData) {
        openAIChatAssistant.sendMessageAndGetInstruction(prompt, imageData).then(response => {
            surflyExtension.surflySession.apiRequest({cmd: 'send_chat_message', message: `✨ Agent: ${response.explanation}`});
            surflyExtension.surflySession.apiRequest({cmd: 'broadcast_message', message: {event_type: 'command', ...response}});
            
            if (sendScreenshots) {
                surflyExtension.surflySession.apiRequest({cmd: 'send_chat_message', message: `✨ Agent: Adding screenshot to the popup..`});    
                surflyExtension.surflySession.apiRequest({cmd: 'broadcast_message', message: {event_type: 'add_screenshot', image_data: imageData, response: response}});
            }
            
            if (autoNext) {
                setTimeout(() => {
                    next();
                }, 3000);
            }
        });
    }
    
    async function initializeMediaStream() {
        try {
            const displayMediaOptions = {
                preferCurrentTab: true,
            };
            mediaStream = await navigator.mediaDevices.getDisplayMedia(displayMediaOptions);
        } catch (err) {
            console.error('Failed to initialize media stream:', err);
        }
    }
    
    async function captureScreen() {
        if (!mediaStream) {
            // If stream was lost/stopped, try to reinitialize
            await initializeMediaStream();
            if (!mediaStream) {
                throw new Error('Failed to initialize media stream');
            }
        }
        
        const track = mediaStream.getVideoTracks()[0];
        const imageCapture = new ImageCapture(track);
        
        try {
            const bitmap = await imageCapture.grabFrame();
            const canvas = document.createElement('canvas');
            canvas.width = bitmap.width;
            canvas.height = bitmap.height;
            const context = canvas.getContext('2d');
            context.drawImage(bitmap, 0, 0, canvas.width, canvas.height);
            return canvas.toDataURL('image/png');
        } catch (err) {
            mediaStream = null;
            throw err;
        }
    }
    
    function agentMessageHandler(message, sender) {
        console.log('[popup.html] agentMessageHandler: message received: ', message);
        if (message.event_type === 'chat_message') {
            if (message.message[0] === '/') {
                const command = message.message.split(' ')[0].slice(1);
                const params = message.message.split(' ').slice(1);

                switch (command) {
                    case 'start':
                    case 'prompt':
                    case 's':
                    case 'p':
                        prompt = params.join(' ');
                        next();
                        break;
                    case 'next':
                    case 'n':
                        next();
                        break;
                    case 'auto':
                    case 'a':
                        autoNext = params[0] === 'on';
                        break;
                    case 'screenshots':
                    case 'ss':
                        sendScreenshots = params[0] === 'on';
                        break;
                    case 'answer':
                        nextAction(params.join(' '), lastImageData);
                        break;
                }
            }
        }
    }
    
    function userMessageHandler(message, sender) {
        console.log('[popup.html] userMessageHandler: message received: ', message);
        if (message.event_type === 'add_screenshot') {
            const screenshotElement = document.getElementById('screenshots');
            const screenshot = document.createElement('div');
            screenshot.innerHTML = `<img src="${message.image_data}" alt="Screenshot" width="640"><p>${JSON.stringify(message.response)}</p>`;
            screenshotElement.appendChild(screenshot);
        }
    }
    
    function init() {
        let handlerAdded = false;
        surflyExtension.surflySession.onMessage.addListener(message => {
            if (message?.msg === 'get_session_participants' && !handlerAdded) {
                const me = message.participants.find(participant => !!participant.self);
                handlerAdded = true;

                surflyExtension.surflySession.onMessage.addListener(userMessageHandler);
                if (!me) {
                    surflyExtension.surflySession.onMessage.addListener(agentMessageHandler);
                }
            }
        })
        
        surflyExtension.surflySession.apiRequest({cmd: 'get_session_participants'})
    }
    
    setTimeout(init, 1000)
</script>
